# âœï¸ Handwritten Digits Classification using Neural Networks

ğŸ‘¨â€ğŸ’» Project Summary:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
This project classifies handwritten digits (0â€“9) using a basic feedforward neural network (also known as a dense or fully connected network) trained on the famous MNIST dataset. This forms the starting point for understanding deep learning and prepares you for more advanced architectures like CNNs.

ğŸ“‚ Dataset:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€¢ ğŸ“¦ Dataset Used: `keras.datasets.mnist`
â€¢ ğŸ§  Description: 28x28 grayscale images of handwritten digits
â€¢ ğŸ‘¨â€ğŸ“ Total Training Samples: 60,000
â€¢ ğŸ§ª Total Testing Samples: 10,000

ğŸ› ï¸ Project Flow:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1. ğŸ“¥ **Data Loading** â€” Loaded the MNIST dataset from Keras.
2. ğŸ” **Data Visualization** â€” Matplotlib used to view samples.
3. ğŸ”„ **Data Preprocessing** â€” 
   â€¢ Normalized pixel values by dividing by 255  
   â€¢ Flattened 2D images (28x28) into 1D vectors (784)
4. ğŸ§  **Model Building** â€”
   â€¢ Input Layer: 784 neurons  
   â€¢ Hidden Layer: 100 neurons with ReLU activation  
   â€¢ Output Layer: 10 neurons with Softmax activation
5. ğŸ§ª **Model Training** â€” Trained over 5 epochs with `adam` optimizer.
6. ğŸ“Š **Evaluation** â€” Evaluated the model on test data using `model.evaluate`.
7. ğŸ” **Prediction & Visualization** â€” Used `model.predict` to classify and visualize predictions.
8. ğŸ’¾ **Model Saving & Loading** â€” Saved the model using `.h5` format.

âš™ï¸ Model Architecture:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€¢ **Input Layer**: 784 features (flattened 28x28 image)  
â€¢ **Hidden Layer**: 100 neurons, ReLU activation  
â€¢ **Output Layer**: 10 neurons, Softmax activation (for digits 0â€“9)

ğŸ“ˆ Accuracy/Loss:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€¢ âš¡ Without Hidden Layer + No Scaling â†’ Accuracy â‰ˆ 88%, High Loss  
â€¢ âš¡ With Hidden Layer + No Scaling â†’ Accuracy â‰ˆ 94%  
â€¢ âœ… With Hidden Layer + Scaling â†’ Accuracy â‰ˆ 98%, Low Loss  

ğŸ§  Key Observations:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€¢ ğŸ”¼ Increasing epochs improves accuracy and reduces loss.  
â€¢ ğŸ“‰ Scaling (normalization) significantly boosts performance.  
â€¢ ğŸ”¥ Softmax is essential for multi-class classification.

ğŸ¯ Conclusion:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Even with a basic neural network structure, we achieved strong classification performance by:
â€¢ Flattening the image  
â€¢ Normalizing the data  
â€¢ Using one hidden layer with ReLU  
â€¢ Softmax for multi-class prediction

This is the foundation of Deep Learning, and prepares you for CNNs ğŸ”¥

ğŸ’¾ To Run:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```bash
pip install tensorflow keras matplotlib numpy
python handwritten_digits_classification.py
```

ğŸ§ª Optional: To test model loading
```python
from tensorflow import keras
model = keras.models.load_model('digits_model.h5')
```

ğŸš€ Next Steps:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€¢ Deploy this using **Streamlit** to accept user-drawn/uploaded images  
â€¢ Try a **Convolutional Neural Network (CNN)** to boost performance  
â€¢ Add more **data augmentation** to improve robustness
